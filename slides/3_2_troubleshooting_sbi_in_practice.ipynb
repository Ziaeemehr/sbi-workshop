{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd24006e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sbi.inference import SNLE, SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "from sbi.simulators.linear_gaussian import (\n",
    "    linear_gaussian,\n",
    "    samples_true_posterior_linear_gaussian_uniform_prior,\n",
    ")\n",
    "import torch\n",
    "from sbi.utils import BoxUniform\n",
    "import matplotlib.pyplot as plt\n",
    "from sbi.analysis import pairplot\n",
    "import sbibm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c24388",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What could go wrong (and how to fix it)\n",
    "\n",
    "## 1. Session: Stay in the SBI bubble: \n",
    "\n",
    "- assume valid simulator and prior\n",
    "\n",
    "<img src=\"janfb/figures/bubble_zacktionman_Flickr.jpg\" align=\"center\" alt=\"beadexample\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c4c4ca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What could go wrong and how to fix it\n",
    "\n",
    "## 2. Session: the full Bayesian workflow\n",
    "\n",
    "- model building, prior checks -> inference -> posterior checks\n",
    "<img src=\"janfb/figures/what-if-i-told-you-this-is-not-fully-bayesian.jpg\" align=\"center\" alt=\"beadexample\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5436d44",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What could go wrong (and how to fix it)\n",
    "\n",
    "## 1. Session: Stay in the SBI bubble: assume valid simulator and prior\n",
    "\n",
    "<img src=\"janfb/figures/bubble_zacktionman_Flickr.jpg\" align=\"center\" alt=\"beadexample\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0306625d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"janfb/figures/bubble_zacktionman_Flickr.jpg\" align=\"right\" width=\"100\"/>\n",
    "\n",
    "## What could go wrong?\n",
    "\n",
    "- the density estimator is off\n",
    "\n",
    "- MCMC samples are off (likelihood based methods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92280eb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"janfb/figures/bubble_zacktionman_Flickr.jpg\" align=\"right\" width=\"100\"/>\n",
    "\n",
    "## What could be the reason?\n",
    "\n",
    "1) training not converged \"properly\" / too little training data\n",
    "    \n",
    "2) density estimator lacks flexibility\n",
    "\n",
    "3) summary statistics (or embedding net) not informative (not discussed today)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c369090c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"janfb/figures/bubble_zacktionman_Flickr.jpg\" align=\"right\" width=\"100\"/>\n",
    "\n",
    "## How to diagnose it?\n",
    "\n",
    "- training and inference logs:\n",
    "    - validaton and training loss convergence\n",
    "    - more to come...\n",
    "    - (MCMC convergence statistics)\n",
    "\n",
    "- posterior predictive checks\n",
    "    - sample from posterior and simulate\n",
    "    - compare to $x_o$\n",
    "    \n",
    "- simulation-based calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8f9703",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 1: Training not converged\n",
    "\n",
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2187b86d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Gaussian simulator\n",
    "def simulator(theta, scale=0.5):\n",
    "    # Sample from standard normal, shift with mean.\n",
    "    return scale * torch.randn(theta.shape) + theta\n",
    "\n",
    "num_dim = 3\n",
    "simulator_scale = 0.5\n",
    "num_samples = 1000\n",
    "# Uniform prior.\n",
    "prior = BoxUniform(-5 * torch.ones(num_dim), 5 * torch.ones(num_dim))\n",
    "x_o = torch.ones(1, num_dim)\n",
    "# True posterior\n",
    "true_samples = simulator_scale * torch.randn(num_samples, num_dim) + x_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66132333",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# run simulations\n",
    "num_simulations = 20  # Little training data.\n",
    "theta = prior.sample((num_simulations,))\n",
    "x = simulator(theta, scale=simulator_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b922a4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# run inference\n",
    "inferer = SNPE(prior, density_estimator=\"mdn\").append_simulations(theta, x)\n",
    "density_estimator = inferer.train()\n",
    "posterior = inferer.build_posterior()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909a45cd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### SBI posterior is off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ce893",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Draw posterior samples and plot 1 and 2-D marginals.\n",
    "posterior_samples = posterior.sample((num_samples,), x=x_o)\n",
    "pairplot([posterior_samples, true_samples], upper=\"scatter\", limits=[[-5, 5]], figsize=(8, 8));\n",
    "plt.legend(['sbi-posterior' ,'true-posterior']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f2d3ef",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### How can we detect this? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995af20f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Diagnostics\n",
    "\n",
    "### SBI training logs with Tensorboard\n",
    "\n",
    "- In a separate terminal window in the same folder run:\n",
    "\n",
    "`tensorboard --logdir sbi-logs/`\n",
    "\n",
    "- This will open a Tensorboard on a localhost, usually http://localhost:6006/\n",
    "\n",
    "- Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3042f7f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Tensorboard demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbec3aac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Diagnostics\n",
    "\n",
    "### Posterior predictive checks\n",
    "\n",
    "- General idea: samples from the posterior should reproduce the observed data $x_o$\n",
    "    - plus simulator noise\n",
    "\n",
    "- Samples from the posterior plugged into the simulator should cluster around $x_o$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a72866",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example: Posterior predictive checks with true posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29821d2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Simulate with true posterior samples from above.\n",
    "posterior_predictive_samples = simulator(true_samples)\n",
    "# Plot on top of x_o\n",
    "pairplot([posterior_predictive_samples], upper=\"scatter\", points_colors=\"k\", points=x_o, limits=[[-5, 5]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc63efc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Practical 1 (10 min):\n",
    "\n",
    "1. Run the inference from the previous example.\n",
    "2. Start Tensorboard and inspect the training logs\n",
    "    - especially training log probs and validation log probs\n",
    "    - what do you observe? did the training converge properly?\n",
    "3. Run posterior predictive checks with the trained density estimator.\n",
    "4. Change the training settings and re-run the inference. \n",
    "5. Repeat the checks, did it help?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61020f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 2: Choice of density estimator\n",
    "\n",
    "- SBI offers different types of density estimators: \n",
    "    - mixture density networks (of Gaussians) (MDN)\n",
    "    - normalizing flows\n",
    "\n",
    "- MDN are fast in training, sampling and evaluation\n",
    "- Flows are more flexible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e7f29b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Normalizing flows\n",
    "\n",
    "<img src=\"janfb/figures/nutshell_Kletr-Shutterstock.jpg\" align=\"left\" alt=\"beadexample\" width=\"250\"/> \n",
    "\n",
    "- transform a simple base distribution to a complex target distribution\n",
    "\n",
    "- transforms can be trained with NNs (under certain assumptions)\n",
    "\n",
    "- concatenating transforms -> powerful (conditional) density estimator\n",
    "\n",
    "- implemented in `sbi`: \n",
    "    - masked autoregressive flows (\"MAF\")\n",
    "    - neural spline flows (\"NSF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e5e12",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 2: Inference on the two-moon task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e397c334",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Load two-moon task from sbi-benchmark package\n",
    "import sbibm\n",
    "task = sbibm.get_task(\"two_moons\")\n",
    "simulator = task.get_simulator()\n",
    "prior = task.get_prior_dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2669e382",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Simulate\n",
    "num_simulations = 10000\n",
    "num_samples = 1000\n",
    "theta = prior.sample((num_simulations,))\n",
    "x = simulator(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f369f2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# run inference with MDN\n",
    "inferer = SNPE(prior, density_estimator=\"mdn\").append_simulations(theta, x)\n",
    "density_estimator = inferer.train()\n",
    "posterior = inferer.build_posterior(density_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb954b87",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MDN posterior fails to learn the two moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56bea09",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Draw posterior samples and plot 1 and 2-D marginals.\n",
    "x_o = task.get_observation(1)\n",
    "mdn_samples = posterior.sample((num_samples,), x=x_o)\n",
    "true_samples = task.get_reference_posterior_samples(1)[:num_samples,]\n",
    "pairplot([mdn_samples, true_samples], upper=\"scatter\", limits=[[-1, 1]], figsize=(7, 7));\n",
    "plt.legend([\"mdn-posterior\", \"true-posterior\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3847f556",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Practical 2: Changing density estimators (10 min)\n",
    "\n",
    "### Tasks\n",
    "1. Change the density estimator to a flow and train again.\n",
    "2. Compare to the reference posterior samples using `pairplot`.\n",
    "3. [Optional] The `density_estimator` argument takes a `string` or a function. By passing a `string` you get a density estimator with default settings, by passing a function you can pass your custom density estimator. Have a look at `sbi.utils.get_nn_models` to see how to build such a customised density estimator using the function `posterio_nn(...)` or `likelihood_nn(...)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6519d374",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 3: Leakage in multi-round inference\n",
    "\n",
    "- in multi-round inference we run inference over multiple rounds\n",
    "- in every new round we simulate new training data not from the prior, but from the recent posterior estimate\n",
    "- this requires some correction and algorithmic sugar (see SNPE A, B and C papers)\n",
    "- but can improve data efficiency: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e85857",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Problem 3: Leakage in multi-round inference\n",
    "\n",
    "- SNPE-C is the method of choice but comes with a drawback as well:\n",
    "- for complex problems with bounded priors posterior mass tends to leak outside of the prior bounds\n",
    "- this can get extreme: with 99,9% of the mass leaking out (warning in `sbi`)\n",
    "\n",
    "### Solutions\n",
    "- sample posterior with MCMC or classic rejection sampling.\n",
    "- use likelihood based approaches if possible (depends on kind of data).\n",
    "- use single round inference ;-) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f27991",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "### Further reading\n",
    "- \n",
    "\n",
    "### Figures\n",
    "- bubble: \n",
    "- nutshell:\n",
    "- GIF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df4f692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
