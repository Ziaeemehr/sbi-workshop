{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876dfe9d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sbi.inference import SNLE, SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "from sbi.simulators.linear_gaussian import (\n",
    "    linear_gaussian,\n",
    "    samples_true_posterior_linear_gaussian_uniform_prior,\n",
    ")\n",
    "import torch\n",
    "from sbi.utils import BoxUniform\n",
    "import matplotlib.pyplot as plt\n",
    "from sbi.analysis import pairplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39881c7b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What could go wrong (and how to fix it)\n",
    "\n",
    "## 1. Stay in the SBI bubble: assume valid simulator and prior\n",
    "\n",
    "<img src=\"janfb/figures/bubble_zacktionman_Flickr.jpg\" align=\"center\" alt=\"beadexample\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee35dae2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"janfb/figures/bubble_zacktionman_Flickr.jpg\" align=\"right\" width=\"100\"/>\n",
    "\n",
    "### What could go wrong?\n",
    "\n",
    "- the density estimator is off\n",
    "\n",
    "- in case of likelihood based approaches: MCMC samples are off\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd74545",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"janfb/figures/bubble_zacktionman_Flickr.jpg\" align=\"right\" width=\"100\"/>\n",
    "\n",
    "### Possible reasons\n",
    "\n",
    "1) training not converge properly / too little training data\n",
    "    \n",
    "2) density estimator lacks flexibility\n",
    "\n",
    "3) summary statistics (or embedding net) not informative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942f1272",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"janfb/figures/bubble_zacktionman_Flickr.jpg\" align=\"right\" width=\"100\"/>\n",
    "\n",
    "### Diagnostics?\n",
    "\n",
    "- training logs:\n",
    "    - check validaton loss for convergence\n",
    "    - ...\n",
    "\n",
    "- (MCMC convergence statistics)\n",
    "\n",
    "- posterior predictive checks\n",
    "    - sample from posterior and simulate\n",
    "    - compare to $x_o$\n",
    "    \n",
    "- simulation-based calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132b9d93",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Problem 1: Training not converged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cc0cd6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Gaussian simulator\n",
    "def simulator(theta, scale=0.5):\n",
    "    # Sample from standard normal, shift with mean.\n",
    "    return scale * torch.randn(theta.shape) + theta\n",
    "\n",
    "num_dim = 3\n",
    "simulator_scale = 0.5\n",
    "num_samples = 1000\n",
    "# Uniform prior.\n",
    "prior = BoxUniform(-5 * torch.ones(num_dim), 5 * torch.ones(num_dim))\n",
    "x_o = torch.ones(1, num_dim)\n",
    "# True posterior\n",
    "true_samples = simulator_scale * torch.randn(num_samples, num_dim) + x_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4349410e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# run simulations\n",
    "num_simulations = 20  # Little training data.\n",
    "theta = prior.sample((num_simulations,))\n",
    "x = simulator(theta, scale=simulator_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc5104b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# run inference\n",
    "inferer = SNPE(prior, density_estimator=\"mdn\").append_simulations(theta, x)\n",
    "density_estimator = inferer.train()\n",
    "posterior = inferer.build_posterior()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ab3b7a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SBI posterior is off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c650c21c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Draw posterior samples and plot 1 and 2-D marginals.\n",
    "posterior_samples = posterior.sample((num_samples,), x=x_o)\n",
    "pairplot([posterior_samples, true_samples], upper=\"scatter\", limits=[[-5, 5]], figsize=(8, 8));\n",
    "plt.legend(['sbi-posterior' ,'true-posterior']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2db998d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Diagnostics\n",
    "\n",
    "### SBI training logs with Tensorboard\n",
    "\n",
    "- In a separate terminal window in the same folder run:\n",
    "\n",
    "`tensorboard --logdir sbi-logs/`\n",
    "\n",
    "- This will open a Tensorboard on a localhost, usually http://localhost:6006/\n",
    "\n",
    "- Demo..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf686963",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Diagnostics\n",
    "\n",
    "### Posterior predictive checks\n",
    "\n",
    "- General idea: samples from the posterior should reproduce the observed data $x_o$\n",
    "    - plus simulator noise\n",
    "\n",
    "- Samples from the posterior plugged into the simulator should cluster around $x_o$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5d130",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Simulate true posterior samples\n",
    "posterior_predictive_samples = simulator(true_samples)\n",
    "# Plot on top of x_o\n",
    "pairplot([posterior_predictive_samples], upper=\"scatter\", points_colors=\"k\", points=x_o, limits=[[-5, 5]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c155823",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Practical 1 (10 min):\n",
    "\n",
    "1. Run the inference as it is\n",
    "2. Start Tensorboard and inspect the training logs\n",
    "    - especially training log probs and validation log probs\n",
    "    - what do you observe? did the training converge properly?\n",
    "3. Run posterior predictive checks\n",
    "4. Change the training settings and re-run the inference\n",
    "5. Repeat the checks, did it help?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad6cbb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Problem 2: Choice of density estimator\n",
    "\n",
    "- SBI offers different types of density estimators: \n",
    "    - mixture density networks (of Gaussians) (MDN)\n",
    "    - normalizing flows\n",
    "\n",
    "- MDN are fast in training, sampling and evaluation\n",
    "- Flows are more flexible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5411da2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Normalizing flows\n",
    "\n",
    "<img src=\"janfb/figures/nutshell_Kletr-Shutterstock.jpg\" align=\"left\" alt=\"beadexample\" width=\"300\"/> \n",
    "\n",
    "- transform a simple base distribution to a complex target distribution\n",
    "\n",
    "- transforms can be trained with NNs (with certain assumptions)\n",
    "\n",
    "- concatenating transforms -> powerful (conditional) density estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec38940",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 2: Inference on the two-moon task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c500bea8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Load two-moon task from sbi-benchmark package\n",
    "import sbibm\n",
    "task = sbibm.get_task(\"two_moons\")\n",
    "simulator = task.get_simulator()\n",
    "prior = task.get_prior_dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490ad821",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Simulate\n",
    "num_simulations = 10000\n",
    "num_samples = 1000\n",
    "theta = prior.sample((num_simulations,))\n",
    "x = simulator(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01f3f38",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# run inference with MDN\n",
    "inferer = SNPE(prior, density_estimator=\"mdn\").append_simulations(theta, x)\n",
    "density_estimator = inferer.train()\n",
    "posterior = inferer.build_posterior(density_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466605a3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MDN posterior fails to learn the two moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ff570",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Draw posterior samples and plot 1 and 2-D marginals.\n",
    "x_o = task.get_observation(1)\n",
    "mdn_samples = posterior.sample((num_samples,), x=x_o)\n",
    "true_samples = task.get_reference_posterior_samples(1)[:num_samples,]\n",
    "pairplot([mdn_samples, true_samples], upper=\"scatter\", limits=[[-1, 1]], figsize=(7, 7));\n",
    "plt.legend([\"mdn-posterior\", \"true-posterior\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5e0f34",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Practical 2: Changing density estimators (10 min)\n",
    "\n",
    "### Tasks\n",
    "1. Change the density estimator to a flow and train again\n",
    "2. Compare to the reference posterior samples using `pairplot`.\n",
    "3. [Optional] Have a look at `sbi.utils.get_nn_models` to see how to build a customised density estimator using the function `posterio_nn(...)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58680a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What could go wrong and how to fix it\n",
    "\n",
    "## 2. Take a step back: look at the full Bayesian workflow\n",
    "<img src=\"janfb/figures/what-if-i-told-you-this-is-not-fully-bayesian.jpg\" align=\"center\" alt=\"beadexample\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcc83bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "### Further reading\n",
    "- \n",
    "\n",
    "### Figures\n",
    "- bubble: \n",
    "- nutshell:\n",
    "- GIF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4210be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
